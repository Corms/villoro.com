# --------------------------------------------------------------------------------------------------
# Basic metadata
# --------------------------------------------------------------------------------------------------
code: tables_format
title: Storing tables efficiently
date: "2019-03-21"
image: nginx_gunicorn_square.jpg
highlight: True

tags:
  - Python

tags_filter:
  - Python

# --------------------------------------------------------------------------------------------------
# Extra info. This will add a button with href to the url
# --------------------------------------------------------------------------------------------------
# link: 
#   text: 
#   url: 


# --------------------------------------------------------------------------------------------------
# Content
# --------------------------------------------------------------------------------------------------
brief_markdown: |
  Brief

# image_head:
#   filename: 
#   caption: 

use_chartjs: True

content_markdown: |

  When working with **pandas** people usually need to store one or more tables. There are a lot of different formats to do that. In this post I am going to compare the performance between them.

  ## How test will be done
  To do the tests I downloaded 3 datasets of different sizes:

  * [Small](https://www.kaggle.com/contactprad/bike-share-daily-data) (56 KB)
  * [Medium](https://www.kaggle.com/safegraph/visit-patterns-by-census-block-group) (233 MB)
  * [Large](https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title) (6.62 GB)

  I downloaded them from kaggle, one of the best places to find datasets.

  The formats that I will test are:

  * csv
  * feather
  * msgpack
  * parquet
  * pickle
  * xlsx

  ## Test 1: Simple test
  First of all I will check how they perform without changing any parameters. I will do 100 iterations with the small dataset and 10 with the medium one.

  ### Size small and iterations 100 with all extensions

  First of all the average reading/writing times for each format.

  <canvas id="chart_s0_i100_time" style="width:100%;height:300px;"></canvas>

  > It seems that `xlsx` is a slow option

  ### Size medium and iterations 10 with all extensions

  <canvas id="chart_s1_i10_time" style="width:100%;height:300px;"></canvas>

  With the medium dataframe the results are very similar.

  > `xlsx` is a slow solution. I would only recommend it for small dataframes.

  <canvas id="chart_s1_i10_size" style="width:100%;height:300px;"></canvas>

  Regarding the file size both `xlsx` and `parquet` outperform the rest. If you look the pandas documentation you will see that **all extensions except `xlsx` and `feather` allow different types of compression.** Also `parquet` uses a more agresive compression by default. We need to test the formats and the different compressions.




scripts: |
  <script>
    var chart_s0_i100_time = new Chart("chart_s0_i100_time", {
      type: 'bar',
      data: {
        labels: ['csv', 'feather', 'msgpack', 'parquet', 'pickle', 'xlsx'],
        datasets: [
          {
            label: 'read',
            backgroundColor: "#64B5F6", 
            data: [0.005766, 0.002291, 0.001909, 0.004744, 0.002504, 0.121258],
          },
          {
            label: 'write',
            backgroundColor: "#FFA726",
            data: [0.027968, 0.006942, 0.005825, 0.008368, 0.007167, 0.221087],
          }
        ],
      },
      options: {
        title: {
          display: true,
          text: 'Read/write average time with small dataframe (56 KB)'
        },
        scales: {
          yAxes: [{
            scaleLabel: {
              display: true,
              labelString: 'Time [seconds]'
            }
          }]
        }
      }
    });

    var chart_s1_i10_time = new Chart("chart_s1_i10_time", {
      type: 'bar',
      data: {
        labels: ['csv', 'feather', 'msgpack', 'parquet', 'pickle', 'xlsx'],
        datasets: [
          {
            label: 'read',
            backgroundColor: "#64B5F6", 
            data: [3.355233, 0.672547, 0.644967, 0.974831, 0.581298, 39.258066],
          },
          {
            label: 'write',
            backgroundColor: "#FFA726",
            data: [6.443962, 1.004818, 1.486842, 1.969526, 1.476743, 95.992012],
          }
        ],
      },
      options: {
        title: {
          display: true,
          text: 'Read/write average time with medium dataframe (233 MB)'
        },
        scales: {
          yAxes: [{
            scaleLabel: {
              display: true,
              labelString: 'Time [seconds]'
            }
          }]
        }
      }
    });
    var chart_s1_i10_size = new Chart("chart_s1_i10_size", {
      type: 'bar',
      data: {
        labels: ['csv', 'feather', 'msgpack', 'parquet', 'pickle', 'xlsx'],
        datasets: [
          {
            label: 'read',
            backgroundColor: "#64B5F6", 
            data: [236.1, 213.38, 210.09, 96.37, 207.54, 68.21],
          },
        ],
      },
      options: {
        title: {
          display: true,
          text: 'File size with medium dataframe (233 MB)'
        },
        scales: {
          yAxes: [{
            scaleLabel: {
              display: true,
              labelString: 'File size [MB]'
            }
          }]
        }
      }
    });
  </script>
  